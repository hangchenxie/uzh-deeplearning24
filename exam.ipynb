{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 2\n",
    "\n",
    "- Compute gradient manually\n",
    "\n",
    "See Assignment 2 directory for the code."
   ],
   "id": "c2ccf6fae6b7af8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 3\n",
    "\n",
    "- Two-layer neural network\n",
    "- Gradient implementation\n",
    "- Iterative gradient descent\n",
    "\n",
    "See Assignment 3 directory for the code."
   ],
   "id": "cecc79ede7095cff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 4\n",
    "\n",
    "- Stochastic gradient descent\n",
    "\n",
    "See Assignment 4 directory for the code."
   ],
   "id": "ce069abe87c63af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def min_max_scaler(train_data, test_data):\n",
    "\n",
    "    # Compute the correct statistics\n",
    "    min_val = torch.min(train_data)\n",
    "    max_val = torch.max(train_data)\n",
    "\n",
    "    # Scale the training data\n",
    "    train_data_scaled = (train_data - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Scale the test data using the same min and max values\n",
    "    test_data_scaled = (test_data - min_val) / (max_val - min_val)\n",
    "\n",
    "    return train_data_scaled, test_data_scaled, min_val, max_val\n",
    "\n",
    "\n",
    "def inverse_min_max_scaler(scaled_data, min_val, max_val):\n",
    "\n",
    "    # Revert the scaling\n",
    "    original_data = scaled_data * (max_val - min_val) + min_val\n",
    "\n",
    "    return original_data\n",
    "\n",
    "def standardize(X_train, X_val):\n",
    "    # compute statistics\n",
    "    mean = torch.mean(X_train, dim=0)\n",
    "    std = torch.std(X_train, dim=0)\n",
    "\n",
    "    # standardize both X_train and X_val\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_val = (X_val - mean) / std\n",
    "\n",
    "    return X_train, X_val\n",
    "\n",
    "label_emb = label_emb / np.linalg.norm(label_emb, axis=1, keepdims=True)\n",
    "\n"
   ],
   "id": "1ecc202a0be405ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 5\n",
    "\n",
    "- Binary cross-entropy loss\n",
    "- Binary classification network\n",
    "- Categorical cross-entropy loss\n",
    "- Categorical classification network"
   ],
   "id": "aefcb9cfc44212ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    " \n",
    "loss = torch.nn.BCELoss()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def Network(D, K, O):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(D, K),\n",
    "        torch.nn.Tanh(),\n",
    "        torch.nn.Linear(K, O)\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.SGD(Network().parameters(), lr=0.01)"
   ],
   "id": "eb956397010d1c7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 6\n",
    "\n",
    "- Sequential networks\n",
    "- Convolutional neural networks\n",
    "- Pooling layers and stride\n",
    "- Flattening layers\n",
    "- Device"
   ],
   "id": "72a86d976696fb98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='data/',\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "dataloder = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "def fully_connected(D, K1, K2, O):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(D, K1),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(K1, K2),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(K2, O),\n",
    "    )\n",
    "\n",
    "def convolutional(Q1, Q2, O):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, Q1, kernel_size=7, stride=1, padding=0),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Conv2d(Q1, Q2, kernel_size=5, stride=1, padding=2),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(Q2*5*5, O),\n",
    "    )\n"
   ],
   "id": "ee39b00b6d946691"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 7\n",
    "\n",
    "- Pre-trained networks\n",
    "- Extract deep features"
   ],
   "id": "97ec5b8977a8e9a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "imagenet_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),                                    # Resize the image such that the shorter side has size 256\n",
    "    torchvision.transforms.CenterCrop(224),                                # Take the center crop of size 224x224\n",
    "    torchvision.transforms.ToTensor(),                                     # Convert the image into a tensor\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],           # Normalize pixel values with mean\n",
    "                                     std=[0.229, 0.224, 0.225])            # Normalize pixel values with standard deviation\n",
    "])\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "dataset = ImageFolder('data/', transform=imagenet_transform)\n",
    "\n",
    "network = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "# Make sure to freeze all the layers of the network.\n",
    "for param in network.parameters():\n",
    "    param.requires_grad = False  # Freeze all the layers of the network\n",
    "\n",
    "features = network.fc.in_features\n",
    "\n"
   ],
   "id": "96509f83d748c2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercice 8\n",
    "\n",
    "- Network Module definition\n",
    "- Autograd Function"
   ],
   "id": "47ffee150d2df788"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AdaptedSoftMax(torch.autograd.Function):\n",
    "\n",
    "    # implement the forward propagation\n",
    "    @staticmethod\n",
    "    def forward(ctx, logits, targets):\n",
    "        # compute the log probabilities via log_softmax\n",
    "        log_probs = torch.nn.functional.log_softmax(logits, dim=1)\n",
    "        # save required values for backward pass\n",
    "        ctx.save_for_backward(logits, targets)\n",
    "        # compute loss\n",
    "        loss = -torch.sum(log_probs * targets, dim=1).mean()\n",
    "        return loss\n",
    "\n",
    "    # implement Jacobian\n",
    "    @staticmethod\n",
    "    def backward(ctx, result):\n",
    "        # get results stored from forward pass\n",
    "        logits, targets = ctx.saved_tensors\n",
    "        # compute derivative of loss w.r.t. the logits\n",
    "        y = torch.nn.functional.softmax(logits, dim=1)\n",
    "        dJ_dz = result * (y - targets)\n",
    "        # return the derivatives; none for derivative for the targets\n",
    "        return dJ_dz, None\n",
    "\n",
    "# DO NOT REMOVE!\n",
    "# here we set the adapted softmax function to be used later\n",
    "adapted_softmax = AdaptedSoftMax.apply\n",
    "\n",
    "\n",
    "class Network (torch.nn.Module):\n",
    "    def __init__(self, Q1, Q2, K, O):\n",
    "        # call base class constrcutor\n",
    "        super(Network,self).__init__()\n",
    "        # define convolutional layers\n",
    "        self.conv1 = torch.nn.Conv2d(1, Q1, 7, stride=1, padding=0)\n",
    "        self.conv2 = torch.nn.Conv2d(Q1, Q2, 5, stride=1, padding=2)\n",
    "        # pooling and activation functions will be re-used for the different stages\n",
    "        self.pool = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.act = torch.nn.PReLU()\n",
    "        # define fully-connected layers\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(Q2*5*5, K)\n",
    "        self.fc2 = torch.nn.Linear(K, O)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # compute first layer of convolution, pooling and activation\n",
    "        a = self.act(self.pool(self.conv1(x)))\n",
    "        # compute second layer of convolution, pooling and activation\n",
    "        a = self.act(self.pool(self.conv2(a)))\n",
    "        # get the deep features as the output of the first fully-connected layer\n",
    "        deep_features = self.fc1(self.flatten(a))\n",
    "        # get the logits as the output of the second fully-connected layer\n",
    "        logits = self.fc2(deep_features)\n",
    "        # return both the logits and the deep features\n",
    "        return logits, deep_features"
   ],
   "id": "84a77f6e7f13b874"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 9\n",
    "\n",
    "- Combining submodules\n",
    "- MSE loss\n",
    "\n"
   ],
   "id": "c4cc5088e61671c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MixedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root='./data', purpose=\"train\", transform=None, anomaly_size=2000):\n",
    "        # load MNIST dataset based on \"purpose\"\n",
    "        self.mnist_dataset = torchvision.datasets.MNIST(root=root, train=(purpose==\"train\"), download=True, transform=transform)\n",
    "\n",
    "        # load FashionMNIST dataset when \"purpose\" is \"anomaly_detection\" and randomly select samples with size \"anomaly_size\"\n",
    "        fashion_mnist_dataset = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "        idx = np.random.choice(len(fashion_mnist_dataset), anomaly_size, replace=False)\n",
    "        self.fashion_mnist_dataset = torch.utils.data.Subset(fashion_mnist_dataset, idx)\n",
    "\n",
    "        self.dataset = self.mnist_dataset if purpose != \"anomaly_detection\" else torch.utils.data.ConcatDataset([self.mnist_dataset, self.fashion_mnist_dataset])\n",
    "\n",
    "    def __len__(self):\n",
    "        # return length of the desired dataset based on its purpose\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # perform appropriate actions on the data, target, and its data type indicator (return 1 for regular and -1 for anomalous)\n",
    "        image, target = self.dataset[idx]\n",
    "        data_type = 1 if idx < len(self.mnist_dataset) else -1\n",
    "\n",
    "        return image, target, data_type\n",
    "    \n",
    "loss = torch.nn.MSELoss()"
   ],
   "id": "78c353efa5f3a8de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 10\n",
    "\n",
    "- Custom dataset\n",
    "- Sequence item prediction\n"
   ],
   "id": "6274077e2fa40bda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_sequences_targets(data: torch.Tensor, S):\n",
    "\n",
    "    # Initialize empty lists to hold the input sequences and the corresponding target values\n",
    "    X, T = [], []\n",
    "\n",
    "    # Go through the data to extract sequences based on S\n",
    "    for i in range(len(data)-S):\n",
    "        X.append(data[i:i+S])\n",
    "        T.append(data[i+S])\n",
    "\n",
    "    # Convert lists of sequences and targets into PyTorch tensors\n",
    "    return torch.stack(X), torch.stack(T)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, S):\n",
    "\n",
    "        # store the data and targets as required\n",
    "        self.X, self.T = create_sequences_targets(data, S)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # return input and target value for the given index\n",
    "        return self.X[index], self.T[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the length of this dataset\n",
    "        return len(self.X)"
   ],
   "id": "627d632a1970ed5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exercise 11\n",
    "\n",
    "-Backpropagation to input"
   ],
   "id": "2306ef50a25ed615"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tell autograd that we need the gradient for the input\n",
    "x.requires_grad = True\n",
    "# forward input\n",
    "z = network(x)\n",
    "# compute loss and gradient\n",
    "J = loss(z, t)\n",
    "J.backward()\n",
    "\n",
    "# get the gradient\n",
    "gradient = x.grad\n",
    "\n",
    "def FGS(x, t, network, loss, alpha=0.3):\n",
    "    # tell autograd that we need the gradient for the input\n",
    "    x.requires_grad = True\n",
    "    # forward input\n",
    "    z = network(x)\n",
    "    # compute loss and gradient\n",
    "    J = loss(z, t)\n",
    "    J.backward()\n",
    "\n",
    "    # get the gradient\n",
    "    gradient = x.grad\n",
    "    # create FGS adversarial sample\n",
    "    adversarial_sample = torch.clamp(x + alpha * torch.sign(gradient), 0, 1)\n",
    "\n",
    "    return adversarial_sample\n",
    "\n",
    "def FGV(x, t, network, loss, alpha=0.6):\n",
    "    # tell autograd that we need the gradient for the input\n",
    "    x.requires_grad = True\n",
    "    # forward input\n",
    "    z = network(x)\n",
    "    # compute loss and gradient\n",
    "    J = loss(z, t)\n",
    "    J.backward()\n",
    "\n",
    "    # get the gradient\n",
    "    gradient = x.grad\n",
    "    # create FGV adversarial sample\n",
    "    # max_abs_gradient = torch.max(torch.abs(gradient.view(gradient.shape[0], -1)), dim=1, keepdim=True)[0].view(-1, 1, 1, 1)\n",
    "    max_abs_gradient = torch.max(torch.abs(gradient))\n",
    "    adversarial_sample = torch.clamp(x + alpha * gradient / max_abs_gradient, 0, 1)\n",
    "\n",
    "    return adversarial_sample\n",
    "\n",
    "for epoch in range(epochs): \n",
    "# DO NOT FORGET: \n",
    "    optimizer.zero_grad() \n",
    "    Z = network(X_train) \n",
    "    J = loss(Z, T_train) \n",
    "    J.backward() \n",
    "    perform parameter update\n",
    "    optimizer.step()  \n",
    "    compute validation accuracy \n",
    "    with torch.no_grad():\n",
    "    Z = network(X_val)  \n",
    "    acc = accuracy(Z, T_val)\n",
    "\n",
    "network.train()\n",
    "for x,t in train_loader:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    # compute output for current batch\n",
    "    z = network(x)\n",
    "    # compute loss\n",
    "    J = loss(z,t)\n",
    "    # compute gradient\n",
    "    optimizer.zero_grad()\n",
    "    J.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "network.eval()\n",
    "# iterate over validation set samples\n",
    "loss = 0\n",
    "for x,t in validation_loader:\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    with torch.no_grad():\n",
    "        # classify original samples\n",
    "        z = network(x)\n",
    "        loss += loss(z,t).item() * x.size(0)\n",
    "        \n",
    "        "
   ],
   "id": "7528b60332c582a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
