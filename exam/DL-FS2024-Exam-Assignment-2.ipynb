{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Classification of the Gender from the First Name\n",
    "\n",
    "In this assignment, we have the task to design and implement a recurrent neural network, particularly, an Elman network using pytorch.\n",
    "With this network, we classify first names into being male or female.\n",
    "Here, we only train and evaluate a network on the training data, no separate validation or test set is required.\n",
    "\n",
    "## Input Data\n",
    "\n",
    "The data that we make use of is given online in the UCI data repository: https://archive.ics.uci.edu/dataset/591/gender+by+name\n",
    "\n",
    "The dataset contains names and their gender.\n",
    "Names are represented by a list of characters -- we here will use only lower-case letters and the `-` character.\n",
    "\n",
    "Please run the following code cell to download and extract the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:50:11.314724Z",
     "start_time": "2024-06-14T06:50:07.058166Z"
    }
   },
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "# get data:\n",
    "dataurl = \"https://archive.ics.uci.edu/static/public/591/gender+by+name.zip\"\n",
    "name = \"gender+by+name.zip\"\n",
    "datafile = \"name_gender_dataset.csv\"\n",
    "\n",
    "# Skip downloading if the file already exists\n",
    "if not os.path.exists(datafile):\n",
    "    # Download the file\n",
    "    urllib.request.urlretrieve(dataurl, name)\n",
    "    print(f\"Downloaded {name} successfully.\")\n",
    "\n",
    "    # Extract the zip file\n",
    "    with zipfile.ZipFile(name, 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(f\"Extracted {name} successfully.\")\n",
    "\n",
    "assert os.path.exists(datafile)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded gender+by+name.zip successfully.\n",
      "Extracted gender+by+name.zip successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "We extract all names and all target values.\n",
    "The names are stored in a python list `inputs` with `N=146751` elements, where we filter out any names with non-letter symbols, so that the final set of characters contains 27 elements.\n",
    "Similarly, the gender values are provided in a python list `targets` with `N` elements, where male names are represented by target $t^{[n]}=0$ and female names with $t^{[n]}=1$.\n",
    "\n",
    "Please run the below code to extract input and target data and print some statistics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T06:50:27.678862Z",
     "start_time": "2024-06-14T06:50:27.605013Z"
    }
   },
   "source": [
    "import csv\n",
    "file = csv.reader(open(datafile), delimiter=',')\n",
    "# skip header\n",
    "next(file)\n",
    "\n",
    "unique_chars = {chr(ord(\"a\") + i) : i for i in range(26)}\n",
    "unique_chars[\"-\"] = 26\n",
    "\n",
    "# read data and targets, remove outliers\n",
    "inputs, targets = [], []\n",
    "for splits in file:\n",
    "  t = splits[0].lower()\n",
    "  if any(c not in unique_chars for c in t): continue\n",
    "  inputs.append(splits[0].lower())\n",
    "  targets.append(0 if splits[1] == \"M\" else 1)\n",
    "\n",
    "# print out some statistics\n",
    "N = len(inputs)\n",
    "females = int(sum(targets))\n",
    "print (f\"Collected N={N} names, of which {females} are female and {N-females} are male\")\n",
    "\n",
    "# print out 10 examples and their target values\n",
    "print (f\"The first ten inputs are: {inputs[:10]}\")\n",
    "print (f\"The first ten targets are: {targets[:10]}\")"
   ],
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'gbk' codec can't decode byte 0xa6 in position 7304: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# read data and targets, remove outliers\u001B[39;00m\n\u001B[0;32m     10\u001B[0m inputs, targets \u001B[38;5;241m=\u001B[39m [], []\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m splits \u001B[38;5;129;01min\u001B[39;00m file:\n\u001B[0;32m     12\u001B[0m   t \u001B[38;5;241m=\u001B[39m splits[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlower()\n\u001B[0;32m     13\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(c \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m unique_chars \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m t): \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m: 'gbk' codec can't decode byte 0xa6 in position 7304: illegal multibyte sequence"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c): Character Encoding\n",
    "\n",
    "To make use of the data, each unique character needs to be transformed into a one-hot vector encoding $\\vec x = \\{0.,1.\\}^D$ and $\\sum\\limits_{d=1}^D x_d = 1$ with $D$ being the input dimensionality.\n",
    "\n",
    "Implement a function (or a reasonable data structure) that turns a character into a one-hot vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Obtain the input dimension\n",
    "D = N\n",
    "\n",
    "# ALTERNATIVE 1:\n",
    "# function to encode characters\n",
    "def encoding(c):\n",
    "    torch.zeros(D)[unique_chars[c]] = 1\n",
    "\n",
    "# ALTERNATIVE 2:\n",
    "# data structure that defines the encoding\n",
    "encoding = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d): Dataset Implementation\n",
    "\n",
    "To make use of the data during training, we need to implement a `torch.utils.data.Dataset` that provides the encoded data, and the target values.\n",
    "As usual, you need to implement three functions, which are the constructor `__init__`, the index function `__getitem__` and the number of samples in this dataset via `__len__`.\n",
    "\n",
    "Since we want to make use of a batch, each sample needs to be of a fixed sequence length $S$, which you need to define reasonably.\n",
    "For samples that are shorter than this sequence length, an appropriate padding needs to be implemented.\n",
    "\n",
    "Implement the dataset below.\n",
    "Make sure that the `__getitem__` function returns the encoded name, which is in size $\\mathbb R^{S\\times D}$, possibly including an appropriate padding.\n",
    "Depending on the loss function that you select below, you need to adapt the target $t$ accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "S = 10\n",
    "\n",
    "# create dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, T, S):\n",
    "        # call base class constructor\n",
    "        super(Dataset, self).__init__()\n",
    "        # Anything else?\n",
    "        self.dataset = X\n",
    "        self.targets = T\n",
    "        self.S = S\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # encode sample at the given index with padding\n",
    "        encoded = encoding(self.dataset[index : index + self.S])\n",
    "        # possibly adapt the target value to fit to your loss function\n",
    "        target = encoding(self.targets[index : index + self.S])\n",
    "        # return both the encoded name and the target value\n",
    "        return encoded, target\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of samples in this dataset\n",
    "        return len(self.datase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (e): Elman Network Implementation\n",
    "\n",
    "The Elman network is a sequence processing network that we select to process our encoded names.\n",
    "Particularly, the network is defined by two layers, which are computed as follows:\n",
    "\n",
    "$$\\vec h^{\\{s\\}} = g\\left(\\mathbf W^{(1)} \\vec x^{\\{s\\}} + \\mathbf W^{(r)} \\vec h^{\\{s-1\\}}\\right)$$\n",
    "$$\\vec z^{\\{s\\}} = \\mathbf W^{(2)} \\vec h^{\\{s\\}}$$\n",
    "\n",
    "where $\\mathbf W^{(1)}$, $\\mathbf W^{(r)}$, and $\\mathbf W^{(2)}$ are learnable matrices, $g(\\cdot)$ is an appropriate activation function as selected in Task (a), and $\\vec h^{\\{s\\}}$ and $\\vec z^{\\{s\\}}$ are, respectively, the hidden representation and the logit output of the network for sequence element $\\vec x^{\\{s\\}}$.\n",
    "\n",
    "Finally, you need to implement the Elman network defined by the above equations as a `torch.nn.Module`.\n",
    "Implement the network by making use of the weight matrices (or reasonable representations thereof) in the dimensionalities defined in Task (a).\n",
    "Please be aware that inputs will be given in batches: $\\mathcal X\\in\\mathbb R^{B\\times S\\times D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the Elman network\n",
    "class ElmanNet(torch.nn.Module):\n",
    "    def __init__(self, D, H, C):\n",
    "        # call super class constructor\n",
    "        super(ElmanNet, self).__init__()\n",
    "        # instantiate all required elements in appropriate dimensionalities\n",
    "        self.W1 = torch.nn.Linear(D, H)\n",
    "        self.Wr = torch.nn.Linear(H, H)\n",
    "        self.W2 = torch.nn.Linear(H, C)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # obtain the shape of the sample\n",
    "        B, S, D = x.shape\n",
    "        # initialize the hidden unit in the required dimensionality\n",
    "        H = torch.zeros(B, H)\n",
    "        # iterate through the sequence\n",
    "        for s in range(S):\n",
    "            # update the hidden representation with the current sequence element\n",
    "            H = self.activation(self.W1(x[:, s, :]) + self.Wr(H))\n",
    "            # anything else to be done here?\n",
    "            Z = self.W2(H)\n",
    "            \n",
    "        # return whatever is required to be returned here\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (f): Network Training\n",
    "\n",
    "Finally, we want to train our Elman network on the provided data.\n",
    "We need to instantiate the Elman network, possibly passing the required parameters.\n",
    "Also, an appropriate loss function needs to be selected -- here we can ignore the imbalanced nature of the dataset.\n",
    "Instantiate the data loader with reasonable parameters, and an optimizer used to train the network.\n",
    "Train the network for 10 epochs, and compute the training set accuracy during the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the network\n",
    "network = ElmanNet(D, H, C)\n",
    "\n",
    "# instantiate the loss\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# instantiate an optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# instantiate data loader\n",
    "dataloader = torch.utils.data.DataLoader(Dataset(), batch_size=32, shuffle=True)\n",
    "\n",
    "# iterate through training set only\n",
    "for epoch in range(10):\n",
    "    # iterate through the training dataset\n",
    "    correct = 0\n",
    "    accuracy = 0\n",
    "    for x, t in dataloader:\n",
    "        # train the network on the current batch\n",
    "        optimizer.zero_grad()\n",
    "        Z = network(x)\n",
    "        J = loss(Z, t)\n",
    "        J.backward()\n",
    "        optimizer.step()\n",
    "        # compute the training set accuracy\n",
    "        correct += torch.sum(torch.argmax(Z, dim=1) == t).item()\n",
    "        accuracy = correct / len(dataloader.dataset)\n",
    "\n",
    "    # print the training set accuracy\n",
    "    print(\"Epoch\", epoch, \"accuracy\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLExam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
