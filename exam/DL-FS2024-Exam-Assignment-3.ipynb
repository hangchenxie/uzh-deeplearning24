{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Image Classification with Convolutional Neural Network\n",
    "\n",
    "A convolutional network should be designed for the automatic classification of digits in street house numbers.\n",
    "Particularly, we make use of the SVHN dataset, which is composed of 10 different classes, one for each digit, and implemented in the `torchvision.datasets`: https://pytorch.org/vision/stable/generated/torchvision.datasets.SVHN.html\n",
    "The color images are of size $32\\times32$ pixels, where the house number of interest is in the center of the image.\n",
    "\n",
    "Additionally to the network, you are supposed to implement at least one regularization techniques that you defined in Task (b).\n",
    "Note that such techniques can be implemented in the network design as well as in the training loop.\n",
    "Make sure that you adapt your code as to accommodate these regularization techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (c) Dataset and Data Loaders\n",
    "\n",
    "Instantiate the training and the test set of the SVHN dataset.\n",
    "Set the original data to download automatically.\n",
    "Apply appropriate transforms to the training and the test datasets.\n",
    "Instantiate data loaders for the two datasets with reasonable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "# instantiate the training set\n",
    "training_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),                                    # Resize the image such that the shorter side has size 256\n",
    "    torchvision.transforms.CenterCrop(224),                                # Take the center crop of size 224x224\n",
    "    torchvision.transforms.ToTensor(),                                     # Convert the image into a tensor\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],           # Normalize pixel values with mean\n",
    "                                     std=[0.229, 0.224, 0.225])            # Normalize pixel values with standard deviation\n",
    "])\n",
    "training_dataset = torchvision.datasets.SVHN(root=\"data\", split=\"train\", transform=training_transform, download=True)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# instantiate the test set\n",
    "testing_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),                                    # Resize the image such that the shorter side has size 256\n",
    "    torchvision.transforms.CenterCrop(224),                                # Take the center crop of size 224x224\n",
    "    torchvision.transforms.ToTensor(),                                     # Convert the image into a tensor\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],           # Normalize pixel values with mean\n",
    "                                     std=[0.229, 0.224, 0.225])            # Normalize pixel values with standard deviation\n",
    "])\n",
    "testing_dataset = torchvision.datasets.SVHN(root=\"data\", split=\"test\", transform=testing_transform, download=True)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Samples\n",
    "\n",
    "We provide the source code to visualize some samples of the training set.\n",
    "We also print the class labels for the data, which are arranged in the same grid as the images.\n",
    "Feel free to run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "fig, axes = pyplot.subplots(5,10,figsize=(10,5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        image, label = training_dataset[i*10+j]\n",
    "        axes[i][j].imshow(image.permute(1,2,0))\n",
    "        axes[i][j].axis(\"off\")\n",
    "        print(label, end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task (d): Convolutional Network Implementation\n",
    "\n",
    "The convolutional network is designed with the following layers:\n",
    "\n",
    "- A convolution layer with kernel size $5\\times5$, 32 output channels, stride 1, padding 2 in vertical dimension only.\n",
    "- A maximum pooling layer of size $2\\times2$.\n",
    "- A convolution layer with kernel size $5\\times5$, 64 output channels, stride 1, padding 2 in vertical dimension only.\n",
    "- A maximum pooling layer of size $2\\times2$.\n",
    "- A convolution layer with kernel size $5\\times5$, 128 output channels, stride 1, padding 2 in vertical dimension only.\n",
    "- A fully-connected layer with $K$ inputs and $O$ outputs.\n",
    "\n",
    "Please add additional layers in your implementation whenever you see the need for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# implement and instantiate network\n",
    "\n",
    "network = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=(0,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=(0,2)),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=(0,2)),\n",
    "            torch.nn.Linear(128*5*5, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task (e): Network Training\n",
    "\n",
    "Instantiate an appropriate loss function and an optimizer, with reasonable parameters. \n",
    "Train the network for 10 epochs on the GPU device (during development, you can use the CPU device, but at the end, the code should be able to run on the GPU). \n",
    "Compute the average training set loss within an epoch. \n",
    "Compute the test set accuracy at the end of each epoch, and print it together with the training set loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate loss function\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# instantiate optimizer\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# make sure to train everything on the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    # train the network on the training set\n",
    "    for x, t in training_dataloader:\n",
    "        train_loss = 0\n",
    "        # train on the batch\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        z = network(x)\n",
    "        J = loss(z, t)\n",
    "        optimizer.zero_grad()\n",
    "        J.backward()\n",
    "        optimizer.step()\n",
    "        # aggregate training set loss\n",
    "        train_loss += J.item() * x.size(0)\n",
    "\n",
    "    # evaluate of the test set\n",
    "    for x, t in testing_dataloader:\n",
    "        test_loss = 0\n",
    "        x = x.to(device)\n",
    "        t = t.to(device)\n",
    "        with torch.no_grad():\n",
    "        # classify original samples\n",
    "            z = network(x)\n",
    "            test_loss += loss(z,t).item() * x.size(0)\n",
    "\n",
    "    # print average training set loss and test set accuracy\n",
    "    print(f\"Epoch {epoch}: training loss {train_loss}, test accuracy {test_loss / len(testing_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLExam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
